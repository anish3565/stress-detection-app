# import streamlit as st

# def chatbot_ui():
#     # Initialize session state variables if they do not exist
#     if "chat_open" not in st.session_state:
#         st.session_state.chat_open = False
#     if "messages" not in st.session_state:
#         st.session_state.messages = []

#     # Chatbot toggle button
#     if st.button("üí¨ Chat with AI"):
#         st.session_state.chat_open = not st.session_state.chat_open  # Toggle chat window

#     # Chatbot UI
#     if st.session_state.chat_open:
#         with st.container():
#             st.markdown(
#                 """
#                 <style>
#                 .chat-container {
#                     position: fixed;
#                     bottom: 20px;
#                     right: 20px;
#                     width: 350px;
#                     background-color: white;
#                     padding: 10px;
#                     border-radius: 10px;
#                     box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);
#                 }
#                 .chat-messages {
#                     max-height: 250px;
#                     overflow-y: auto;
#                     padding: 5px;
#                     border-bottom: 1px solid #ddd;
#                 }
#                 .chat-input {
#                     width: 100%;
#                     padding: 5px;
#                 }
#                 </style>
#                 <div class="chat-container">
#                     <div class="chat-messages">
#                 """,
#                 unsafe_allow_html=True,
#             )

#             # Display previous chat messages
#             for msg in st.session_state.messages:
#                 st.markdown(f"**{msg['role']}:** {msg['content']}")

#             st.markdown("</div>", unsafe_allow_html=True)

#             # User input for chatbot
#             user_input = st.text_input("Type your message here...", key="chat_input")

#             # Process input when the user clicks "Send"
#             if st.button("Send") and user_input:
#                 st.session_state.messages.append({"role": "You", "content": user_input})

#                 # Simulate bot response (Replace with API call)
#                 bot_response = "I'm here to help! How are you feeling?"  # Replace this with actual API response
#                 st.session_state.messages.append({"role": "Bot", "content": bot_response})

#                 # Refresh UI
#                 st.rerun()

#             # Close button
#             if st.button("Close Chat"):
#                 st.session_state.chat_open = False
#                 st.rerun()

#             st.markdown("</div>", unsafe_allow_html=True)

# # Ensure this script runs only when executed directly (not when imported)
# if __name__ == "__main__":
#     chatbot_ui()

# import streamlit as st
# import requests
# import json
# from typing import Iterator

# class OllamaAPI:
#     def __init__(self, base_url: str = "http://127.0.0.1:11434"):
#         self.base_url = base_url

#     def generate_response(self, prompt: str, model: str = "mistral:7b") -> Iterator[str]:
#         """Generate streaming response from Ollama API"""
#         try:
#             response = requests.post(
#                 f"{self.base_url}/api/generate",
#                 json={
#                     "model": model,
#                     "prompt": prompt,
#                     "stream": True
#                 },
#                 stream=True
#             )
#             response.raise_for_status()
            
#             for line in response.iter_lines():
#                 if line:
#                     json_response = json.loads(line)
#                     if chunk := json_response.get('response', ''):
#                         yield chunk
                        
#         except Exception as e:
#             yield f"Error: {str(e)}"

# def initialize_session_state():
#     """Initialize session state variables"""
#     if "chat_open" not in st.session_state:
#         st.session_state.chat_open = False
#     if "messages" not in st.session_state:
#         st.session_state.messages = []
#     if "ollama_api" not in st.session_state:
#         st.session_state.ollama_api = OllamaAPI()

# def chatbot_ui():
#     # ‚ö†Ô∏è Removed `st.set_page_config()` to prevent multiple calls
    
#     # Initialize session state
#     initialize_session_state()
    
#     # Add custom CSS
#     st.markdown("""
#         <style>
#         .chat-container {
#             border: 1px solid #ddd;
#             border-radius: 10px;
#             padding: 20px;
#             margin-bottom: 20px;
#             background-color: white;
#         }
#         .message-container {
#             margin: 10px 0;
#             padding: 10px;
#             border-radius: 5px;
#         }
#         .user-message {
#             background-color: #e3f2fd;
#             margin-left: 20%;
#             margin-right: 5%;
#         }
#         .bot-message {
#             background-color: #f5f5f5;
#             margin-left: 5%;
#             margin-right: 20%;
#         }
#         .message-text {
#             margin: 0;
#             padding: 5px;
#         }
#         </style>
#     """, unsafe_allow_html=True)
    
#     # Main chat interface
#     st.title("A afe Place to talk!üòÑ")
    
#     # Chat messages container
#     chat_container = st.container()
    
#     # Input container
#     with st.container():
#         col1, col2 = st.columns([6, 1])
#         with col1:
#             user_input = st.text_input("How are you doing today", key="user_input")  # üîÑ No direct session_state modification
#         with col2:
#             send_button = st.button("Send")
    
#     # Process user input
#     if send_button and user_input:
#         # Add user message to chat
#         st.session_state.messages.append({"role": "user", "content": user_input})
        
#         # Create a placeholder for the streaming response
#         with chat_container:
#             message_placeholder = st.empty()
#             full_response = ""
            
#             # Stream the response
#             for chunk in st.session_state.ollama_api.generate_response(user_input):
#                 full_response += chunk
#                 message_placeholder.markdown(f"**Bot**: {full_response}")
        
#         # Add the complete bot response to messages
#         st.session_state.messages.append({"role": "bot", "content": full_response})

#     # Display chat history
#     with chat_container:
#         for msg in st.session_state.messages:
#             message_class = "user-message" if msg["role"] == "user" else "bot-message"
#             st.markdown(
#                 f"""
#                 <div class="message-container {message_class}">
#                     <p class="message-text"><strong>{msg["role"].title()}:</strong> {msg["content"]}</p>
#                 </div>
#                 """,
#                 unsafe_allow_html=True
#             )

# if __name__ == "__main__":
#     chatbot_ui()
